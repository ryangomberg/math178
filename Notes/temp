\begin{flushleft}
If you have ever studied the brain, we describe its functions as one, complex, entangled web. It is comprised of billions of neurons which pass information to neurotransmitters. These so-called \textit{messengers} ``light up'' when they are activated by a neuron's incoming signal and pass on the new information to other neurons. This process is repeated until a terminal branch is reached, which then processes the information to different parts of the body. New information then gets sent back to the brain, creating a feedback loop. Ultimately, it is only with a neural network that we can perform simple tasks (i.e. movement, sensations, processing information).\\

\subsection{Overview of Neural Networks}
Neural networks in machine learning, in its simplest form, is no different from our how brain works. The overarching idea is to initialize a set of neurons and send them through \textit{activation functions}. These functions light up and transmit new information to the next activation function. The process repeats until every set of activation functions has been processed; the final set our neurons is our output, or the terminal branch in this sense. Depending on our objective, the networkâ€™s output may be a single binary value, as in classification problems, or multiple continuous values.\\
\vspace{2mm}
The input layer consists of the set of $P$ observations $X = (X_1, X_2, \cdot \cdot \cdot, X_p)$, each assigned to a neuron. Additionally, each neuron is given a weight, which describes how strong of a \textit{connection} it has between other neurons. After the input layer, neurons then get passed into \textit{hidden layers}, each containing \textit{activation functions}. These functions are \textit{non-linear} transformations of our input neurons and generally are not fixed in advance, but instead learned as we train the network. Hidden layers can be thought of ``working behind the scenes," or the intermediate steps of the neural network. Finally, the output layer uses the most recent activation of neurons as its input, resulting in a function $f(X)$. The diagram shown below summarizes the structure of a neural network, containing the input layer, one hidden layer, and output layer.
\end{flushleft}
\begin{center}

\end{center}
\begin{flushleft}

\end{flushleft}
...This is known as a \textbf{single layer neuron network}, namely because it only has one hidden layer.\\
activation function (more on this later)
